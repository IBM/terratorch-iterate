run_name: test_benchmark_swin_3d_no_timm
experiment_name: benchmark_test
defaults:
  trainer_args:
    precision: bf16-mixed # for these new models pretrained with bf16-mixed we should probably finetune with bf16-mixed
    max_epochs: 2
  terratorch_task:
    model_args:
      pretrained: False
      backbone:
        class_path: swin3d.swin3d_backbone.Swin3dBackbone
        init_args:
          patch_size:
            - 4
            - 4
            - 4
          window_size:
            - 2
            - 7
            - 7
          embed_dim: 96
          depths:
            - 2
            - 2
            - 6
            - 2
          in_chans: 6
          num_heads:
            - 3
            - 16
            - 12
            - 24
    model_factory: PrithviModelFactory
    optimizer: AdamW
tasks:
  # - name: agb
  #   type: regression
  #   loss: rmse
  #   bands:
  #     - BLUE
  #     - GREEN
  #     - RED
  #     - NIR_NARROW
  #     - SWIR_1
  #     - SWIR_2
  #   ignore_index: -1
  #   backbone_args:
  #     drop_path_rate: 0.3
  #   max_epochs: 1
  #   head_args:
  #     final_act: torch.nn.ReLU
  #     learned_upscale_layers: 2
  #   datamodule: benchmark/resources/dataset_specifications/agb.yaml
  #   decoder: FCNDecoder
  #   metric: val/RMSE
  - name: sen1floods11
    type: segmentation
    loss: ce
    ignore_index: -1
    bands:
      - BLUE
      - GREEN
      - RED
      - NIR_NARROW
      - SWIR_1
      - SWIR_2
    max_epochs: 10
    datamodule: benchmark/resources/dataset_specifications/sen1floods11.yaml
    decoder: FCNDecoder
    metric: val/loss
  - name: eurosat
    type: classification
    loss: ce
    bands:
      - BLUE
      - GREEN
      - RED
      - NIR_NARROW
      - SWIR_1
      - SWIR_2
    num_classes: 10
    max_epochs: 10
    datamodule: benchmark/resources/dataset_specifications/eurosat.yaml
    decoder: IdentityDecoder
    metric: val/loss
  # optimization_except:
  #   - decoder_channels
  #   - head_dropout
  # - decoder
n_trials: 4
save_models: false
storage_uri: /dccstor/geofm-finetuning/carlosgomes/benchmark/
optimization_space:
  batch_size:
      - 8
      - 32
      - 64
  lr:
    max: 1e-3
    min: 1e-6
    type: real
    log: true
